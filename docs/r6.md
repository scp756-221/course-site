## Reading 6

1. [Domain-Specific Hardware Accelerators](https://cacm.acm.org/magazines/2020/7/245701-domain-specific-hardware-accelerators/fulltext)


## Key points

1. GPU is the most commonly deployed 'domain-specific accelerator' technology. The emerging so-called quantum computers (e.g., [D-Wave](https://www.dwavesys.com/quantum-computing) or Amazon's recently announced [AWS Braket](https://aws.amazon.com/about-aws/whats-new/2020/08/quantum-computing-available-aws-through-amazon-braket/)) can be seen as accelerators of sort for even more specialized problems/algorithms.  

2. Concurrently with mass adoption of GPU for AI (see [here](https://www.datanami.com/2020/10/07/aws-cuts-prices-for-sagemaker-gpu-instances/) or [here](https://cloud.google.com/ai-platform/training/docs/using-gpus)), ASIC for AI have also emerged. Notable examples include [Google's TPU](https://medium.com/@jonathan_hui/ai-chips-tpu-3fa0b2451a2d) and Apple's family of ["Neural Engine"](https://github.com/hollance/neural-engine).

3. You may skip the sections **Balancing Specialization and Generality**, **Total Cost of Ownership** and **Accelerator Design** as they get deep into very specific applications/algorithms and the engineering process of designing a DSA/GPU. 

## Your Turn

   Take 30 minutes for [Quiz 6](https://coursys.sfu.ca/2022sp-cmpt-756-g1/+q6/). 
